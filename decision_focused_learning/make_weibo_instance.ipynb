{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_user = \"../data/weibo/userProfile.pkl\"\n",
    "file_labels = \"../data/weibo/labels_1000.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of User data \n",
    "First approach : without categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_user_num : \n",
      "|    id |   bi_followers_count |   followers_count |   friends_count |   statuses_count |\n",
      "|------:|---------------------:|------------------:|----------------:|-----------------:|\n",
      "| 10029 |                  142 |             11573 |             378 |             1226 |\n",
      "| 10057 |                   72 |               212 |             315 |              305 |\n",
      "| 10111 |                   93 |               322 |             252 |              619 |\n",
      "| 10145 |                  310 |              3264 |             540 |             1484 |\n",
      "| 10211 |                  123 |              5704 |             242 |              169 |\n",
      "shape : (1655678, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user = pd.read_pickle(file_user)\n",
    "df_user.index = df_user['id'].astype(np.int64)\n",
    "\n",
    "def featvec(feat, clist):\n",
    "    \"\"\"\n",
    "    onehot encoding\n",
    "    \"\"\"\n",
    "    output = [0] * len(clist)\n",
    "    output[clist.index(feat)] = 1\n",
    "    return output\n",
    "\n",
    "DATE_VAR = ['created_at']\n",
    "NUM_VAR = ['bi_followers_count', 'followers_count', 'friends_count', 'statuses_count']\n",
    "CAT_VAR = ['city', 'verified', 'province', 'verified_type']\n",
    "\n",
    "df_user_num = df_user[NUM_VAR]\n",
    "df_user_num = df_user_num.groupby(df_user_num.index).max() #some userid were 2 time in the dataset 1681085 rows -> 1655678 rows\n",
    "\n",
    "print(\"df_user_num : \\n\" + df_user_num.head(5).to_markdown())\n",
    "print(f\"shape : {df_user_num.shape}\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of ground truths previously estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : \n",
      "|                      |               u |               v |   BT |   JI |   LP |\n",
      "|:---------------------|----------------:|----------------:|-----:|-----:|-----:|\n",
      "| (82768, 82768)       | 82768           | 82768           |  1   | 0.5  |  1   |\n",
      "| (7747002, 7747002)   |     7.747e+06   |     7.747e+06   |  1   | 0.5  |  1   |\n",
      "| (8060099, 8060099)   |     8.0601e+06  |     8.0601e+06  |  1   | 0.5  |  1   |\n",
      "| (15058618, 3023198)  |     1.50586e+07 |     3.0232e+06  |  1   | 0.5  |  1   |\n",
      "| (32821757, 32821757) |     3.28218e+07 |     3.28218e+07 |  0.5 | 0.25 |  0.5 |\n",
      "shape : (147693, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_pickle(file_labels)\n",
    "labels.u = labels.u.astype(np.int64)\n",
    "labels.v = labels.v.astype(np.int64)\n",
    "labels.index = pd.MultiIndex.from_tuples(zip(labels['u'],labels['v'])) #important to do .loc[(u,v)]\n",
    "labels = labels.sort_index() # infos are retreived faster\n",
    "labels = labels.drop_duplicates()\n",
    "labels = labels.drop((1637712471, 279405)) #1637712471 is not present in df_user_num (why ?)\n",
    "\n",
    "print(\"labels : \\n\" + labels.head(5).to_markdown())\n",
    "print(f\"shape : {labels.shape}\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to create a matrix of #influencers x #targets x #features (=1.6Billions entries for only 158048 positive influences)\n",
    "\n",
    "So to create one instance we randomly sample 100 influencers and 1000 influencers\n",
    "\n",
    "Is it enough to have positive examples ? yes : roughly 100 / (100x1000) positive labels per prediction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencers =set(labels.groupby('u').count().index)\n",
    "targets = set(labels.groupby('v').count().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INFLUENCERS = 100\n",
    "N_TARGETS = 1000\n",
    "N_FEATURES = 2 * len(NUM_VAR)\n",
    "N_INSTANCES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_influencers = random.sample(influencers, N_INFLUENCERS)\n",
    "sampled_targets = random.sample(targets, N_TARGETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_y(u,v) : \n",
    "    if (u,v) in labels.index : \n",
    "        return labels.loc[(u,v)]['BT']\n",
    "    else : \n",
    "        return 0\n",
    "\n",
    "def create_XY(sampled_influencers, sampled_targets) :\n",
    "    \"\"\"\n",
    "    from 2 sets of influencers and targets, creates features and labels according to the paper format\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.zeros((N_INFLUENCERS, N_TARGETS, N_FEATURES))\n",
    "\n",
    "    for target in range(N_TARGETS):\n",
    "        X[:, target, :] = np.c_[np.array(df_user_num.loc[sampled_influencers]), np.tile(df_user_num.loc[sampled_targets[target]],(N_INFLUENCERS, 1))]\n",
    "\n",
    "    Y = np.zeros((N_INFLUENCERS, N_TARGETS))\n",
    "\n",
    "    for i in range(N_INFLUENCERS):\n",
    "        for j in range(N_TARGETS):\n",
    "            Y[i,j] = fill_y(sampled_influencers[i], sampled_targets[j])\n",
    "    \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving instance 1/100...\n",
      "Saving instance 11/100...\n",
      "Saving instance 21/100...\n",
      "Saving instance 31/100...\n",
      "Saving instance 41/100...\n",
      "Saving instance 51/100...\n",
      "Saving instance 61/100...\n",
      "Saving instance 71/100...\n",
      "Saving instance 81/100...\n",
      "Saving instance 91/100...\n"
     ]
    }
   ],
   "source": [
    "path = 'instances_weibo/'\n",
    "\n",
    "for instance in range(N_INSTANCES) : \n",
    "    sampled_influencers = random.sample(influencers, N_INFLUENCERS)\n",
    "    sampled_targets = random.sample(targets, N_TARGETS)\n",
    "\n",
    "    X,Y = create_XY(sampled_influencers, sampled_targets)\n",
    "    \n",
    "    if instance % (N_INSTANCES // 10) == 0 : print(f\"Saving instance {instance}/{N_INSTANCES}...\")\n",
    "    if os.path.exists(path + f'X{instance}.npz') == False:\n",
    "        np.savez(path + f'X{instance}.npz', X)\n",
    "    if os.path.exists(path + f'Y{instance}.npz') == False:\n",
    "        np.savez(path + f'Y{instance}.npz', Y)\n",
    "    \n",
    "    del(X,Y)\n",
    "print(\"End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc0f5465fe995d1bcad0eb0cccd8f49aa4a13151dec79867121107c7f441e047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-IM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
